{"path":"attached/files/Session_4_Curve_Fitting_2.pdf","text":"NUMERICAL METHODS WEEK 4NUMERICAL METHODS WEEK 4 CURVE FITTING 2CURVE FITTING 2 We continue with Curve Fitting. This week general linear regression. Reading: Capra and Canale, introduction to part 5 and chapter 1 7 . Learning outcomes: Extend the work on Linear Regression to polynomial and multiple variables. Combine Python and analytical solutions or other platforms. Check your code works correctly, via an external reference. MATT WATKINS MWATKINS@LINCOLN.AC.UKMATT WATKINS MWATKINS@LINCOLN.AC.UK FITTING A QUADRATIC FUNCTIONFITTING A QUADRATIC FUNCTION In the case that the largest power of is we have and an overall error function x x2 ( , , ; ) = + + +yi a0 a1 a2 xi a0 a1xi a2x2 i ei This leads to a set of equations Derive the above equations by differentiating with respect to each of the in turn. Write the equations in matrix form , where is a column matrix with entries and is a column matrix with terms that do not depend on the \u0000tting parameters, , and . Solve for , and . Plot your \u0000tted parabola against the data to check the \u0000t. ( , , ) = ( − − −Sr a0 a1 a2 ∑ i=0 N−1 yi a0 a1xi a2x2 i ) 2 δ ( , , )Sr a0 a1 a2 δa0 δ ( , , )Sr a0 a1 a2 δa1 δ ( , , )Sr a0 a1 a2 δa2 ⟹ (n) + (∑ ) + (∑ )a0 xi a1 x2 i a2 ⟹ (∑ ) + (∑ ) + (∑ )xi a0 x2 i a1 x3 i a2 ⟹ (∑ ) + (∑ ) + (∑ )x2 i a0 x3 i a1 x4 i a2 = ∑ yi = ∑ xiyi = ∑ x2 i yi Sr ai Ax = b x , ,a0 a1 a2 b a0 a1 a2 a0 a1 a2 FITTING A QUADRATIC FUNCTIONFITTING A QUADRATIC FUNCTION This leads to a set of equations We can rewrite these equations as Which is of the form δ ( , , )Sr a0 a1 a2 δa0 δ ( , , )Sr a0 a1 a2 δa1 δ ( , , )Sr a0 a1 a2 δa2 ⟹ (n) + (∑ ) + (∑ )a0 xi a1 x2 i a2 ⟹ (∑ ) + (∑ ) + (∑ )xi a0 x2 i a1 x3 i a2 ⟹ (∑ ) + (∑ ) + (∑ )x2 i a0 x3 i a1 x4 i a2 = ∑ yi = ∑ xiyi = ∑ x2 i yi = ⎛ ⎝ ⎜⎜ (∑ )x0 i (∑ )xi (∑ )x2 i (∑ )xi (∑ )x2 i (∑ )x3 i (∑ )x2 i (∑ )x3 i (∑ )x4 i ⎞ ⎠ ⎟⎟ ⎛ ⎝ ⎜ a0 a1 a2 ⎞ ⎠ ⎟ ⎛ ⎝ ⎜ ∑ yi ∑ xiyi ∑ x2 i yi ⎞ ⎠ ⎟ Ax = bGENERAL LINEAR LEAST SQUARESGENERAL LINEAR LEAST SQUARES Simple linear, polynomial and multiple linear regression can be generalised to the following linear least- squares model can now not polynomials in but some prede\u0000ned functions of those positions = ( ) + ( ) + ( ) + ⋯ + ( ) +yi a0z0 xi a1z1 xi a2z2 xi am−1zm−1 xi ei x are . The prede\u0000ned basis functions de\u0000ne the model, only depend on the coordinate. I is called linear least squares as the parameters appear linearly. The s can be highly non-linear in . For instance. \u0000ts this model with and . Where is a single independent variable and is a prede\u0000ned constant. (x), (x), … , (x)z0 z1 zm−1 m basis functions x , , … ,a0 a1 am−1 z x = ⋅ 1 + cos(ω ) + sin(ω )yi a0 a1 xi a2 xi = 1, = cos(ω )z0 z1 x0 = sin(ω )z2 x0 x ω GENERAL LINEAR LEAST SQUARESGENERAL LINEAR LEAST SQUARES We can rewrite in matrix notation as where bold lower case indicates a column vector, and bold uppercase indicates a matrix. contains the calculated values of the basis functions at the measured values of the independent variables: = ( ) + ( ) + ( ) + ⋯ + ( ) +yi a0z0 xi a1z1 xi a2z2 xi am−1zm−1 xi ei y = Za + e Z m n Z = ⎡ ⎣ ⎢ ⎢⎢ ⎢⎢ ( )z0 x0 ( )z0 x1 ⋮ ( )z0 xn−1 ( )z1 x0 ( )z1 x1 ⋮ ( )z1 xn−1 ⋯ ⋯ ⋱ ⋯ ( )zm−1 x0 ( )zm−1 x1 ⋮ ( )zm−1 xn−1 ⎤ ⎦ ⎥ ⎥⎥ ⎥⎥ The column vector contains the observed values of the dependent variable The column vector contains the unknown parameters of the model The column vector contains the observed residuals (errors) y n + 1 = [ , , , , … , ]y T y0 y1 y2 y3 yn−1 a m + 1 = [ , , , … , ]a T a0 a1 a2 am−1 e n + 1 = [ , , , , … , ]e T e0 e1 e2 e3 en−1 GENERAL LINEAR LEAST SQUARESGENERAL LINEAR LEAST SQUARES We can also express error in our model as a sum of the squares much like before: is minimised by taking partial derivatives wrt , which yields which is exactly equivalent to the set of simultaneous equations for we found previously when \u0000tting polynomials. More details can of the derivation can be found , though the notation is a little different. This set of equations is of the form and can be solved using gauss elimination or similar method. Try to redo the earlier \u0000tting problems in this notation / method. Sr = ∑ i=0 n ( − )yi ∑ j=0 m ajzji 2 = ∑ = e = (y − Za (y − Za)e2 i e T ) T Sr a Za = yZ T Z T ai here (http://fourier.eng.hmc.edu/e1 7 6 /lectures/NM/node3 5 .html) Ax = b GENERAL LINEAR LEAST SQUARES - EXAMPLEGENERAL LINEAR LEAST SQUARES - EXAMPLE Suppose we have 1 1 measurements at with measured values = [−3., −2.3, −1.6, −0.9, −0.2, 0.5, 1.2, 1.9, 2.6, 3.3, 4.0]xT Let us \u0000t it to a model of the form = [8.26383742, 6.44045188, 4.74903073, 4.5656476, 3.61011683, 3.32743918, 2.9643915, 1.022yT 1.49110572] = ⋅ 1 + +yi a0 a1e −xi a2e −2xi Our matrix has 3 columns for the basis functions , and \u0000nally . It will have 1 1 rows corresponding to the 1 1 measurements. Then we set up the linear equation problem by forming Z ( ) = 1z0 xi ( ) =z1 xi e −xi =z2 e −2xi Z = [ [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 2 . 0 0 8 5 5 3 6 9 e + 0 1 , 4 . 0 3 4 2 8 7 9 3 e + 0 2 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 9 . 9 7 4 1 8 2 4 5 e + 0 0 , 9 . 9 4 8 4 3 1 5 6 e + 0 1 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 4 . 9 5 3 0 3 2 4 2 e + 0 0 , 2 . 4 5 3 2 5 3 0 2 e + 0 1 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 2 . 4 5 9 6 0 3 1 1 e + 0 0 , 6 . 0 4 9 6 4 7 4 6 e + 0 0 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 1 . 2 2 1 4 0 2 7 6 e + 0 0 , 1 . 4 9 1 8 2 4 7 0 e + 0 0 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 6 . 0 6 5 3 0 6 6 0 e - 0 1 , 3 . 6 7 8 7 9 4 4 1 e - 0 1 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 3 . 0 1 1 9 4 2 1 2 e - 0 1 , 9 . 0 7 1 7 9 5 3 3 e - 0 2 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 1 . 4 9 5 6 8 6 1 9 e - 0 1 , 2 . 2 3 7 0 7 7 1 9 e - 0 2 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 7 . 4 2 7 3 5 7 8 2 e - 0 2 , 5 . 5 1 6 5 6 4 4 2 e - 0 3 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 3 . 6 8 8 3 1 6 7 4 e - 0 2 , 1 . 3 6 0 3 6 8 0 4 e - 0 3 ] , [ 1 . 0 0 0 0 0 0 0 0 e + 0 0 , 1 . 8 3 1 5 6 3 8 9 e - 0 2 , 3 . 3 5 4 6 2 6 2 8 e - 0 4 ] ] ZZ T and Z T Z = [ [ 1 . 1 0 0 0 0 0 0 0 e + 0 1 , 3 . 9 8 8 0 5 2 3 5 e + 0 1 , 5 . 3 5 4 7 5 2 9 2 e + 0 2 ] , [ 3 . 9 8 8 0 5 2 3 5 e + 0 1 , 5 . 3 5 4 7 5 2 9 2 e + 0 2 , 9 . 2 3 3 8 2 5 1 8 e + 0 3 ] , [ 5 . 3 5 4 7 5 2 9 2 e + 0 2 , 9 . 2 3 3 8 2 5 1 8 e + 0 3 , 1 . 7 3 2 9 2 7 3 3 e + 0 5 ] ] yZ T Z T y = [ 3 9 . 3 6 9 7 9 7 7 7 , 2 7 2 . 6 2 3 5 2 7 3 8 , 4 1 2 5 . 6 3 0 7 9 8 5 2 ] STATISTICAL INTERPRETATION OF LEAST SQUARESSTATISTICAL INTERPRETATION OF LEAST SQUARES The matrix contains the variance (diagonal elements) and covariances (off-diagonal elements) of the so can be used to estimate the accuracy of the parameter estimation. ( ZZ T ) −1 ai The solutions of this problem are This means that our \u0000nal model for the data is a = [ 2 . 1 3 7 5 8 9 5 1 , 0 . 5 8 6 0 5 7 3 5 , - 0 . 0 1 5 3 7 5 4 1 ] y = 2.13758951 + 0.58605735 − 0.01537541e −x e −2x We can use the Gauss Jordan method to \u0000nd . The diagonal elements of can be designated as We will call the standard error of our \u0000tted model to the data The variances of our parameters are given by ( ZZ T ) −1 ( ZZ T ) −1 z−1 i,i =sy/x 1 n−m√ [ − ( ( ) + ( ) + ( ) + ⋯ + ( ))∑i=n−1 i=0 yi a0z0 xi a1z1 xi a2z2 xi am−1zm−1 xi ]2 − −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− √ var( ) = ( ) =ai s 2 ai z−1 i,i s2 y/x We can now place error limits on our optimal parameters, . If our model is good, the real data should be approximately normally distributed around our model You can then show that the parameters should have a with degrees of freedom. We can put con\u0000dence limits on the parameters using where is our con\u0000dence, for instance 0 .9 5 to be 9 5 % certain the parameter lies within those bounds and are the . , . . .a0 am−1 t-distribution (https://mattatlincoln.github.io/teaching/statistics/lecture_9 /#/6 /2 ) n − 2 P (true value of the ith parameter is in the interval ( − s( ), + s( )) = cai tc/2,n−2 ai ai tc/2,n−2 ai c tc critical values for the appropriate t distribution (https://www.itl.nist.gov/div8 9 8 /handbook/eda/section3 /eda3 6 7 2 .htm) Perform a \u0000t to the following data. use the model form Calculate an error estimate for the optimal parameters. Note, you can perform the matrix inversion required using , by by using a solver in Eigen and setting the right hand side equal to the unit matrix. Upload your solutions and answers to related questions onto x = { 1 0 . 0 0 , 1 6 . 3 0 , 2 3 . 0 0 , 2 7 . 5 0 , 3 1 . 0 0 , 3 5 . 6 0 , 3 9 . 0 0 , 4 1 . 5 0 , 4 2 . 9 0 , 4 5 . 0 0 , 4 6 . 0 0 , 4 5 . 5 0 , 4 6 . 0 0 , 4 9 . 0 0 , 5 0 . 0 0 } y = { 8 . 9 5 3 , 1 6 . 4 0 5 , 2 2 . 6 0 7 , 2 7 . 7 6 9 , 3 2 . 0 6 5 , 3 5 . 6 4 1 , 3 8 . 6 1 7 , 4 1 . 0 9 5 , 4 3 . 1 5 6 , 4 4 . 8 7 2 , 4 6 . 3 0 1 , 4 7 . 4 9 0 , 4 8 . 4 7 9 , 4 9 . 3 0 3 , 4 9 . 9 8 8 } = ⋅ 1 + +yi a0 a1xi ei Gauss Jordan elimination (https://mattatlincoln.github.io/teaching/numerical_methods/lecture_2 /#/7 ) Blackboard (https://blackboard.lincoln.ac.uk/webapps/bbgs-acxiom-bb_bb6 0 /execute/acxiomGateway? course id= 1 2 7 6 0 3 1 &content id= 2 2 3 8 1 1 1 1 &mode=view) Remember to break the problem down into smaller ones: Can you set up the matrix? Can you \u0000nd the transpose of the matrix? Can you multiply the transposed and non-transposed matrices together? Can you solve the system of linear equations? Z Z SUMMARY AND FURTHER READINGSUMMARY AND FURTHER READING You should be reading additional material to provide a solid background to what we do in class Reading: Capra and Canale, introduction to part 5 and chapter 1 7 . Lots of details inchapters 1 4 and 1 5 of .Numerical Recipes (http://apps.nrbook.com/c/index.html) REUSING CODEREUSING CODE You may dislike having lots of code / routines copied around everytime we reuse something The solution is to other \u0000les or, generally, libraries. We can make our own library \u0000le by copying functions other than m a i n into a \u0000le called ' m y _ l i b r a r y . h ' include This is my example project. Right click on the project name in the pane to right. Then select p r o p e r t i e s . bolded A new window should have appeared, like this: Then click on drop down button in the second column of the the 'Additional Include Directories' row and select edit You should see something like this: Click on the folder icon, and select the directory where you saved your 'my_library.h' \u0000le in To include the Eigen library, save and extract the library (you can \u0000nd it on the front page of the learning resources tab) add the directory containing the extracted Eigen folder to the include path. here is an example. Now I can add a #include line in the \u0000le and use any functions in the library . # i n c l u d e < i o s t r e a m > # i n c l u d e < E i g e n / D e n s e > u s i n g E i g e n : : M a t r i x 2 d ; u s i n g n a m e s p a c e s t d ; i n t m a i n ( ) { M a t r i x 2 d A , b ; A < < 2 , - 1 , - 1 , 3 ; b < < 1 , 0 , 0 , 1 ; c o u t < < \" H e r e i s t h e m a t r i x A : \\ n \" < < A < < e n d l ; c o u t < < \" H e r e i s t h e r i g h t h a n d s i d e b : \\ n \" < < b < < e n d l ; Here is some code to read in a matrix from a csv \u0000le. Assumes the header contains the number of rows then number of columns. # i n c l u d e < i o s t r e a m > # i n c l u d e < E i g e n / D e n s e > # i n c l u d e < f s t r e a m > # i n c l u d e < s t r i n g > u s i n g E i g e n : : M a t r i x X d ; u s i n g n a m e s p a c e s t d ; M a t r i x X d s l u r p D a t a ( ) { s t r i n g n f i l e , t e m p ; i n t N c o l , N r o w ; c o u t < < \" I n s e r t t h e n a m e o f t h e f i l e c o n t a i n i n g t h e c o e f f i c i e n t a n d t h e c o n s t a n t t e r m s \" < < \" \\ n \" ; c i n > > n f i l e ; i f s t r e a m m y F i l e ( n f i l e ) ; / / R e a d t h e s i z e o f t h e m a t r i x i f ( m y F i l e . i s _ o p e n ( ) ) { c o u t < < \" \\ n o p e n e d f i l e \\ n \\ n \" ; g e t l i n e ( m y F i l e , t e m p , ' , ' ) ; WORKED EXAMPLE OF POLYNOMIAL FIT - USING NEW FANCY MATRICESWORKED EXAMPLE OF POLYNOMIAL FIT - USING NEW FANCY MATRICES Get the data into a readable form - I suggest using Excel and the 'Text to Columns' function under the 'DATA' tab The code to read from a csv \u0000le assumes that the \u0000rst row contains the number of rows, then number of columns Save as csv in the same directory as the project you are working on Add in the Eigen library Write routine(s) to calculate the required sums Use Eigen to solve the system of linear equations. See for examples. We'll discuss some of the solvers later. this tutorial (http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html) Full code here # i n c l u d e < i o s t r e a m > # i n c l u d e < E i g e n / D e n s e > # i n c l u d e < f s t r e a m > # i n c l u d e < c m a t h > # i n c l u d e < s t r i n g > u s i n g E i g e n : : M a t r i x X d ; u s i n g E i g e n : : V e c t o r X d ; u s i n g n a m e s p a c e s t d ; M a t r i x X d s l u r p D a t a ( ) { s t r i n g n f i l e , t e m p ; i n t N c o l , N r o w ; c o u t < < \" I n s e r t t h e n a m e o f t h e f i l e c o n t a i n i n g t h e c o e f f i c i e n t a n d t h e c o n s t a n t t e r m s \" < < \" \\ n \" ; c i n > > n f i l e ; i f s t r e a m m y F i l e ( n f i l e ) ; / / R e a d t h e s i z e o f t h e m a t r i x i f ( m y F i l e . i s _ o p e n ( ) ) {","libVersion":"0.5.0","langs":""}