{"path":"attached/files/Session_2_System_of_Linear_Equations_1.pdf","text":"NUMERICAL METHODS WEEK 2NUMERICAL METHODS WEEK 2 SYSTEM OF LINEAR EQUATIONS 1SYSTEM OF LINEAR EQUATIONS 1 We move on to our second session: . Learning outcomes: Recall methods of solution of inhomogeneous systems of linear equations. Elimination methods, Gauss elimination, Gauss-Jordan elimination . Implement and use Gauss-Jordan Elimination to solve systems of equations. Reading: Introduction to Part 3 and chapter 9 of Chapra and Canale. MATT WATKINS MWATKINS@LINCOLN.AC.UKMATT WATKINS MWATKINS@LINCOLN.AC.UK Introduction to systems of linear equations ( ) SOLVING A SYSTEM OF EQUATIONSSOLVING A SYSTEM OF EQUATIONS Suppose we want to solve a system of equations is a matrix of coef\u0000cients of our unknowns, . is a vector of constants. Explicitly this can be written ( for a set of 4 equations with 4 unknowns) as: It can be useful to rewrite this as an Ax = b A x b = ⎛ ⎝ ⎜ ⎜ ⎜ a00 a10 a20 a30 a01 a11 a21 a31 a02 a12 a22 a32 a03 a13 a23 a33 ⎞ ⎠ ⎟ ⎟ ⎟ ⎛ ⎝ ⎜ ⎜ ⎜ x0 x1 x2 x3 ⎞ ⎠ ⎟ ⎟ ⎟ ⎛ ⎝ ⎜ ⎜ ⎜ b0 b1 b2 b3 ⎞ ⎠ ⎟ ⎟ ⎟ augmented matrix ( https://en.wikipedia.org/wiki/Augmented_matrix) ⎛ ⎝ ⎜⎜ ⎜ ⎜ a00 a10 a20 a30 a01 a11 a21 a31 a02 a12 a22 a32 a03 a13 a23 a33 b0 b1 b2 b3 ⎞ ⎠ ⎟⎟ ⎟ ⎟ GAUSSIAN ELIMINATIONGAUSSIAN ELIMINATION TRIANGULARIZATIONTRIANGULARIZATION We reduce the augmented matrix to . Let us take an initial augmented matrix as: pivoting around row 0 , we remove all entries below the diagonal entry in column 0 , row echelon form ( https://en.wikipedia.org/wiki/Row_echelon_form) ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 1 3 1 2 3 1 3 4 2 3 4 −2 4 1 2 10 17 18 27 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 −2 2 4 0 −3 2 −2 5 4 3 10 12 3 22 ⎞ ⎠ ⎟⎟ ⎟ ⎟ Matrix after pivoting around row 0 Then pivoting around row 1 we remove elements below the diagonal in column 1 , pivoting around row 2 ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 −2 2 4 0 −3 2 −2 5 4 3 10 12 3 22 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 0 0 4 0 −3 2 −2 5 9 −2 10 12 15 10 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 0 0 4 0 −3 0 −2 5 9 4 10 12 15 20 ⎞ ⎠ ⎟⎟ ⎟ ⎟ GAUSSIAN ELIMINATIONGAUSSIAN ELIMINATION BACK SUBSTITUTIONBACK SUBSTITUTION From the triangularized augmented matrix we can then solve for Starting at row 3 , only the coef\u0000cient of is non-zero. Converting the augmented notation to real equations using the last row we have Then we can work up the rows x ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 0 0 4 0 −3 0 −2 5 9 4 10 12 15 20 ⎞ ⎠ ⎟⎟ ⎟ ⎟ x3 0 ⋅ + 0 ⋅ + 0 ⋅ + 4 ⋅ = 20 ⟹ = 5x0 x1 x2 x3 x3 0 ⋅ + 0 ⋅ + −3 ⋅ + 9 ⋅x0 x1 x2 x3 0 ⋅ + 0 ⋅ + −3 ⋅ + 9 ⋅ 5x0 x1 x2 = 15 = 15 ⟹ = 10x2 Now row 2 And \u0000nally 0 ⋅ + 2 ⋅ + 0 ⋅ + 5 ⋅x0 x1 x2 x3 0 ⋅ + 2 ⋅ + 0 ⋅ 10 + 5 ⋅ 5x0 x1 = 12 = 12 ⟹ = −6.5x1 2 ⋅ + 2 ⋅ −6.5 + 4 ⋅ 10 + −2 ⋅ 5x0 = 10 ⟹ = −3.5x0 GAUSS ELIMINATIONGAUSS ELIMINATION Use the code to \u0000nd the solutions of the following systems Can you \u0000nd the solutions to this system of equations? Why not? 3 + 4 − 7x0 x1 x2 7 − + 2x0 x1 x2 + 10 − 2x0 x1 x2 = 23 = 14 = 33 1 + 2 + 3x0 x1 x2 4 + 5 + 6x0 x1 x2 7 + 8 + 9x0 x1 x2 = 1 = 2 = 3 GAUSS-JORDAN ELIMINATIONGAUSS-JORDAN ELIMINATION Guass-Jordan elimination is very similar to Gauss elimination. Instead of triangularization, we make a completely diagonal matrix. Or more exactly we reduce the augmented matrix to row echelon form. Initial matrix is: as before The \u0000rst step is the same: pivoting around row 0 reduced ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 1 3 1 2 3 1 3 4 2 3 4 −2 4 1 2 10 17 18 27 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 −2 2 4 0 −3 2 −2 5 4 3 10 12 3 22 ⎞ ⎠ ⎟⎟ ⎟ ⎟ The \u0000rst step is the same: pivoting around row 0 But now, pivoting around row 1 , we remove entries above below the diagonal of column 1 This continues pivoting around row 2 ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 2 2 −2 2 4 0 −3 2 −2 5 4 3 10 12 3 22 ⎞ ⎠ ⎟⎟ ⎟ ⎟ and ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 0 2 0 0 4 0 −3 2 −7 5 9 −2 −2 12 15 10 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 0 2 0 0 0 0 −3 0 5 5 9 4 18 12 15 20 ⎞ ⎠ ⎟⎟ ⎟ ⎟ And \u0000nally, pivoting around row 3 We can then divide each row by the \u0000nal coef\u0000cients to get: And we can just read the solutions for off. ⎛ ⎝ ⎜⎜ ⎜ ⎜ 2 0 0 0 0 2 0 0 0 0 −3 0 0 0 0 4 −7 −13 −30 20 ⎞ ⎠ ⎟⎟ ⎟ ⎟ ⎛ ⎝ ⎜⎜ ⎜ ⎜ 1 0 −0 0 0 1 −0 0 0 0 1 0 0 0 −0 1 −3.5 −6.5 10 5 ⎞ ⎠ ⎟⎟ ⎟ ⎟ x GAUSS-JORDAN ELIMINATION FOR MATRIX INVERSIONGAUSS-JORDAN ELIMINATION FOR MATRIX INVERSION We can solve the equation using exactly the same method: pivoting around row 0 pivoting around row 1 AX = I ⎛ ⎝ ⎜⎜ 2 1 2 1 0 −1 1 −1 2 1 0 0 0 1 0 0 0 1 ⎞ ⎠ ⎟⎟ ⎛ ⎝ ⎜⎜ 2 0 0 1 −0.5 −2 1 −1.5 1 1 −0.5 −1 0 1 0 0 0 1 ⎞ ⎠ ⎟⎟ ⎛ ⎝ ⎜⎜ 2 0 0 0 −0.5 0 −2 −1.5 7 0 −0.5 1 2 1 −4 0 0 1 ⎞ ⎠ ⎟⎟ pivoting around row 2 Scaling the rows, the \u0000nal matrix is: The RHS of the augmented matrix is ⎛ ⎝ ⎜⎜ 2 0 0 0 −0.5 0 0 0 7 0.285714 −0.285714 1 0.857143 0.142857 −4 0.285714 0.214286 1 ⎞ ⎠ ⎟⎟ ⎛ ⎝ ⎜⎜ 1 −0 0 0 1 0 0 −0 1 0.142857 0.571429 0.142857 0.428571 −0.285714 −0.571429 0.142857 −0.428571 0.142857 ⎞ ⎠ ⎟⎟ A −1 GAUSS-JORDAN ELIMINATIONGAUSS-JORDAN ELIMINATION Alter the code for Gauss elimination to instead perform Gauss-Jordan elimination. - I suggest copying your \u0000le for now, renaming rather than altering the previous code directly. - You should change the second loop so that it goes over all rows. - You should add an `if` statement to skip the row with the same index as the column you are working on. - When the matrix is diagonal, divide each row by the value of the remaining diagonal element to get the identity matrix and . - Test regularly as you make the alterations. Solve the same matrix problems as before and check the result is the same. x GAUSS-JORDAN MATRIX INVERSIONGAUSS-JORDAN MATRIX INVERSION Make a new Gauss-Jordan routine that can calculate the inverse of a matrix. - You need to extend the number of columns in the augmented matrix - You need to extend range of the loops that go over the columns Find the inverse of the matrix Check your solution is correct by multiplying the original and inverse matrices. ⎛ ⎝ ⎜ ⎜ ⎜ 2 1 3 1 2 3 1 3 4 2 3 4 −2 4 1 2 ⎞ ⎠ ⎟ ⎟ ⎟ SUMMARY AND FURTHER READINGSUMMARY AND FURTHER READING You should be reading additional material to provide a solid background to what we do in class All the textbooks in the book list on Bb contain sections on solving linear equations. I suggest Chapter 9 of Chapra and Canale for starters. HOMEWORKHOMEWORK Before next week read about extra steps that can be performed to improve elimination methods. Read about LU decomposition of square matrices, Chapter 1 0 of Chapra and Canale. SNAKESNAKE Use the arrow keys start gameJSXGraph v1.4.6 Copyright (C) see https://jsxgraph.org2 – o + ← ↓ ↑ →","libVersion":"0.5.0","langs":""}