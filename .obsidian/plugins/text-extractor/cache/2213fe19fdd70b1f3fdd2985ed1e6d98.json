{"path":"attached/files/Session_3_Curve_Fitting_2.pdf","text":"NUMERICAL METHODS WEEK 3NUMERICAL METHODS WEEK 3 CURVE FITTING 1CURVE FITTING 1 We continue with Curve Fitting. This week polynomial and multiple linear regression. Reading: Capra and Canale, introduction to part 5 and chapter 1 7 . Learning outcomes: Extend the work on Linear Regression to polynomial and multiple variables. Combine C++ and analytical or other platforms. Check your code works correctly, via an external reference. MATT WATKINS MWATKINS@LINCOLN.AC.UKMATT WATKINS MWATKINS@LINCOLN.AC.UK LEAST SQUARES REGRESSION - SUMMARYLEAST SQUARES REGRESSION - SUMMARY we saw in that given our assumption of a straightline the error at each point is given by We take the sum of the squares of the errors as our error criterion. lecture 1 (https://mattatlincoln.github.io/teaching/numerical_methods/lecture_1 /#/) = + +yi a0 a1xi ei = − −ei yi a0 a1xi = = ( − −Sr ∑ i=0 n−1 e2 i ∑ i=0 n−1 yi a0 a1xi) 2 We can \u0000nd an optimal and . and and are the means of the and values. Correlation of the data: covariance of the data divided by the standard deviation of and . a1 a0 =a1 n ∑ − ∑ ∑xiyi xi yi n ∑ − (∑x2 i xi)2 = − = −a0 ∑ yi n a1 ∑ xi n y¯ a1x¯ y¯ x¯ x y = =y¯ 1 N ∑ i=0 N−1 yi x¯ 1 N ∑ i=0 N−1 xi (x, y) x y r = n ∑ − (∑ )(∑ )xiyi xi yi n ∑ − (∑x2 i xi)2 − −−−−−−−−−−−−− √ n ∑ − (∑y2 i yi)2 − −−−−−−−−−−−−− √ EXERCISESEXERCISES Remember in week 1 we looked at \u0000nding sums: What is What is What is Now add an extra array into your code and calculate the following: and for What is What is What is What are and Find the parameters and for a linear regression model of this data. Check your results are correct! I'd suggest using both inspection and Excel. n∑100 n=1 2n∑200 n=2 2∑99 n=0 n2 let  = i, i = 1, 2, … , 10xi let  = 2i + 0.3yi i = 1, 2, … , 10 ∑i xi ∑i yi ∑i xiyi y¯ x¯ a0 a1 POLYNOMIAL LEAST-SQUARES REGRESSIONPOLYNOMIAL LEAST-SQUARES REGRESSION We can easily extend our method to deal with polynomicals: and an overall error function We then take partial derivatives with respect to the parameters ( ) to get a set of equations. Setting these equations equal to zero, writing in matrix form, then solving, gives us the optimal set of parameters. = + + + … + +yi a0 a1xi a2x2 i anxn i ei = ( − − − − … −Sr ∑ i=0 N−1 yi a0 a1xi a2x2 i anxn i ) 2 …a0 an FITTING A QUADRATIC FUNCTIONFITTING A QUADRATIC FUNCTION In the case that the largest power of is we have and an overall error function This leads to a set of equations Derive the above equations by differentiating with respect to each of the in turn. Write the equations in matrix form , where is a column matrix with entries and is a column matrix with terms that do not depend on the \u0000tting parameters, , and . using the data you can \u0000nd on Blackboard for today's session under the assessments tab. Solve for , and . Plot your \u0000tted parabola against the data to check the \u0000t. Extend the derivation to \u0000tting a cubic polynomial and \u0000t to the data on Bb. x x2 = + + +yi a0x0 i a1x1 i a2x2 i ei = ( − − −Sr ∑ i=0 N−1 yi a0x0 i a1x1 i a2x2 i ) 2 (∑ ) + (∑ ) + (∑ )x0 i a0 x1 i a1 x2 i a2 (∑ ) + (∑ ) + (∑ )x1 i a0 x2 i a1 x3 i a2 (∑ ) + (∑ ) + (∑ )x2 i a0 x3 i a1 x4 i a2 = ∑ x0 i yi = ∑ x1 i yi = ∑ x2 i yi Sr ai Ax = b x , ,a0 a1 a2 b a0 a1 a2 a0 a1 a2 MULTIPLE LINEAR REGRESSIONMULTIPLE LINEAR REGRESSION Instead of powers of a single variable, our model for could be that it is a function of several independent variables: Derive the a set of equations for the case of two independent variables Write the equations in matrix form , where is a column matrix with entries Using the following data Solve for , and Plot your \u0000tted function against the data to check the \u0000t yi = + + + + … +yi a0 a1x1i a2x2i a3x3i anxni Ax = b x , ,a0 a1 a2 x1 0 2 2.5 1 4 7 x2 0 1 2 3 6 2 y 5 10 9 0 3 27 a0 a1 a2 LINEARIZATION OF DATA SETSLINEARIZATION OF DATA SETS Multiple Linear Regression is not just limited to obviously linear data. How would you apply multiple linear regression to data that you thought was related by ?y = ⋯a0xa1 1 xa2 2 xan n SUMMARY AND FURTHER READINGSUMMARY AND FURTHER READING You should be reading additional material to provide a solid background to what we do in class Reading: Capra and Canale, introduction to part 5 and chapter 1 7 . Lots of details in chapters 1 4 and 1 5 of .Numerical Recipes (http://apps.nrbook.com/c/index.html)","libVersion":"0.5.0","langs":""}